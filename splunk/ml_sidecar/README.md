# ğŸ“Œ 1. Overview

ML Sidecar is a behavioral analytics engine designed to cluster Windows Authentication logs and compute multi-layer anomaly scores for every event.

It operates as a companion pipeline (â€œsidecarâ€) to Splunk:
Splunk â†’ ML Sidecar (Python) â†’ Enriched Events â†’ KVStore â†’ Dashboards.

Core Components:
- ML Pipeline (Python)
- Feature Extraction
- Adaptive KMeans Clustering (auto-K)
- 4-Layer Composite Anomaly Scoring
- Drift Detection & Auto-Retraining
- KVStore Export (3 collections)
- Splunk Dashboards (User, Cluster, Anomaly Explorer)

The system supports both batch (daily) and incremental operation.

---

# ğŸ“Œ 2. High-Level Pipeline Diagram

```
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚        1) SPLUNK INGESTION (SEARCH)    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                         "Authentication Events" (4624,4625,4672,..)
                                          â”‚
                                          â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚     2) FEATURE EXTRACTION          â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Extracted features:                                                           â”‚
    â”‚  â€¢ hour, day_of_week                                                          â”‚
    â”‚  â€¢ signature_id                                                               â”‚
    â”‚  â€¢ is_private_ip                                                              â”‚
    â”‚  â€¢ src subnet / dest subnet                                                   â”‚
    â”‚  â€¢ user_hour_zscore (hour-mean)/std                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚     3) SCALING (MinMaxScaler)          â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚     4) KMEANS CLUSTERING (AUTO-K)           â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ TRY K âˆˆ {6, 8, 10, 12, 14}                                     â”‚
               â”‚ For each K:                                                   â”‚
               â”‚    â€¢ Fit KMeans                                               â”‚
               â”‚    â€¢ Calculate silhouette score                               â”‚
               â”‚ Select best K                                                 â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ 5) RAW OUTLIER SCORE ( CENTROID DISTANCE)      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ 6) BEHAVIOR ANALYSIS (3 SUPPORTING RARITY SCORES)       â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ SUPPORT SCORE #1 â†’ cluster_rarity                                              â”‚
 â”‚    = 1 âˆ’ freq(user, cluster) / total(user events)                              â”‚
 â”‚                                                                                â”‚
 â”‚ SUPPORT SCORE #2 â†’ signature_rarity                                            â”‚
 â”‚    = 1 âˆ’ P(signature | cluster)                                                â”‚
 â”‚                                                                                â”‚
 â”‚ SUPPORT SCORE #3 â†’ user_hour_score (Z-score)                                   â”‚
 â”‚    = min(|hour - mean_hour| / std_hour , 1)                                    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   7) FINAL ANOMALY SCORE (WEIGHTED)        â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ final_anomaly_score =                                                         â”‚
   â”‚   0.4 * outlier_score                                                         â”‚
   â”‚ + 0.3 * cluster_rarity                                                        â”‚
   â”‚ + 0.2 * signature_rarity                                                      â”‚
   â”‚ + 0.1 * user_hour_score                                                       â”‚
   â”‚                                                                               â”‚
   â”‚ behavior_outlier = (final_score â‰¥ 0.8 ? 1 : 0)                                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚           8) DRIFT DETECTION                   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                              Compare cluster_dist(old vs new)
                                          â”‚
                            Chi-Square p-value < threshold ?
                               YES â†’ Retrain model
                               NO  â†’ Keep model
                                          â”‚
                                          â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              9) RESULT EXPORT â†’ 3 KVSTORE COLLECTIONS                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ auth_events                       â”‚ auth_user_profiles           â”‚ auth_cluster_profiles      â”‚
  â”‚ (event-level enriched records)    â”‚ (user behavior model)        â”‚ (cluster-level summaries)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚       10) SPLUNK DASHBOARDS                â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  DASHBOARD VIEWS                                                              â”‚
   â”‚  - User Behavior Explorer                                                     â”‚
   â”‚  - Cluster Behavior Analyzer                                                  â”‚
   â”‚  - Anomaly Explorer (Top Outliers)                                            â”‚
   â”‚  - Entropy-based risk panel                                                   â”‚
   â”‚  - Final Score Trend Heatmap                                                  â”‚
   â”‚  - Signature Distribution Charts                                              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸ“Œ 2.1. Architecture Overview

```
Splunk Search â†’ ML Sidecar (Python) â†’ KMeans â†’ Anomaly Scores
                                      â†“
                             KVStore Collections
                                      â†“
                           Splunk Dashboards & Alerts
```
Pipeline works as a â€œsidecarâ€:
Gets Splunk logs â†’ processes â†’ writes back to Splunk.

---

# ğŸ“Œ 3. Data Flow
## 3.1 Input

Input SPL (configurable):

```
index=wineventlog EventCode IN (4624,4625,4634,4672,4768,4769)
| table TimeCreated, user, src, dest, signature, signature_id, process, action, src_user
```

> As a default earliest time is 90 days. (This cdan be configured from the settings.yaml file.)

---

# ğŸ“Œ 4. Features
## 4.1 Feature Extraction

The below features are extracted for every authentication events and normalized with MinMaxScaler function.

```
Feature, AÃ§Ä±klama

hour, EtkinliÄŸin saati
dow, HaftanÄ±n gÃ¼nÃ¼
is_private_ip, Kaynak IP Ã¶zel aÄŸ mÄ±?
signature_id, 4624 / 4625 / 4672
src_octet, IP prefix normalizasyonu
hour_zscore(user), KullanÄ±cÄ±ya gÃ¶re saat sapmasÄ±

```

## 4.1 Model Fields
1. Time-based features

```
Feature â†’ Descriptions

hour â†’  User peak login hour modeling (0â€“23). To understand user's temporal behaviour profile
day_of_week â†’  Weekly behavioral rhythms (0=Monday, ...). To understand seasonality of the behaviours.
user_hour_zscore â†’  (hour - mean_hour) / std_hour. Distance from userâ€™s normal login hour.

```

2. Authentication behavior features

```
Feature/AÃ§Ä±klama

signature_id â†’ Windows event ID (4624, 4625, 4672, 4768, 4769). Identity of the logon/failure event.
action_type â†’ success / failure ([1/0]).
privileged_action_flag â†’ 4672 (privileged logon) â†’ 1.

```

3. Source/Destination network features
```
Feature/AÃ§Ä±klama

is_private_ip â†’ if the ip is private (RFC1918), 1, else 0.
src_subnet â†’ A.B normalize subnet (e.g.: 10.10).
dest_subnet â†’ dest subnet (e.g.: 10.10).
external_ip_flag â†’ 1 if source is public (â€œattacker-likeâ€ behaviour). ???

```

4. Statistical / distributional features
```
Feature/AÃ§Ä±klama

user_cluster_hist prior â†’ Past cluster distribution per user.
user_mean_hour â†’ Learned mean login hour.
user_std_hour â†’ Variance in login timing.
```

---

# ğŸ“Œ 5. Clustering

KMeans runs with multiple candidate values:

```
K âˆˆ {6, 8, 10, 12, 14}
```

For each K:
- Train model
- Measure silhouette score
- Select best K

Output:
- cluster_id
- outlier_score (normalized centroid distance)

---

# ğŸ“Œ 6. Composite Anomaly Score (Final Score)

A four-layer hybrid anomaly score:

## 6.1 Layer 1 â€” Raw Outlier Score (outlier_score)

Centroid Distance in the cluster.

```
outlier_score = normalized(centroid_distance)
```

## 6.2 Layer 2 â€” Cluster Rarity (user-based)

The rate at which a user falls into the relevant cluster.

```
cluster_rarity = 1 - ( user_cluster_freq / user_total_events )

```

## 6.3 Layer 3 â€” Signature Rarity (cluster-level)

Based on the cluster's signature distribution:

```
signature_rarity = 1 - P(signature | cluster)
```

## 6.4 Layer 4 â€” User Hour Z-Score

Deviation from the user's own active hour profile.

```
user_hour_score = min( abs(hour - mean) / std , 1 )
```

## ğŸ“Œ 6.5 Final Anomaly Score Formula

```
final_anomaly_score =
    0.4 * outlier_score +
    0.3 * cluster_rarity +
    0.2 * signature_rarity +
    0.1 * user_hour_score
```

Binary Outlier Flag

```
behavior_outlier = 1 if final_anomaly_score >= 0.8 else 0

```

---

# ğŸ“Œ 7. Drift Detection

Cluster distributions are monitored for model stability.

1. Current model meta â†’ cluster_dist
2. New dataset â†’ new_labels
3. Chi-Square test:

```
p = chisquare(new_dist, expected=old_dist)
```
- p < threshold â†’ drift detected (retrain)
- p â‰¥ threshold â†’ model stable

Default threshold: 0.05

---

# ğŸ“Œ 8. Output: KVStore Collections

Pipeline fills 3 collections in the Splunk:

## 8.1 auth_events

All enriched events (most detailed lookup) - 1 row = 1 event. Contains all enriched events including anomaly scores.

Fields:
```
_key
TimeCreated
user
src
dest
src_user
signature
signature_id
action
process

cluster_id
outlier_score
cluster_rarity
signature_rarity
user_hour_score
final_anomaly_score
behavior_outlier
```

## 8.2 auth_user_profiles

User behaviour profiles:
Behavior model for each user.

```
user
dominant_cluster
mean_hour
std_hour
confidence
```

## 8.3 auth_cluster_profiles

Cluster behaviour profiles:
Summaries of each cluster (signature distribution, private IP rate, etc.)

```
cluster_id
event_count
user_count
private_ip_rate
signature_distribution.*
```

---

# ğŸ“Œ 9. Splunk Preparation (Before Running the ML Pipeline)
Before the ML Sidecar can write enriched results back into Splunk, three KVStore-backed lookups and a multi-panel dashboard must be created.
This section describes the full Splunk configuration used by the pipeline.

## ğŸ“Œ 9.1. KVStore Lookups (`transforms.conf`)

The ML pipeline writes three different data structures back into Splunk. Each structure is mapped to a KVStore collection via `transforms.conf`.

`transforms.conf`

```
[auth_cluster_profiles_lookup]
collection = auth_cluster_profiles
external_type = kvstore
fields_list = _key, cluster_id, event_count, user_count, hour_bin_mean, dow_mean, success_rate, private_ip_rate, signature_distribution, label

[auth_user_profiles_lookup]
collection = auth_user_profiles
external_type = kvstore
fields_list = _key, user, dominant_cluster, confidence, mean_hour, std_hour

[auth_events_lookup]
collection = auth_events
external_type = kvstore
fields_list = _key, TimeCreated, user, src, dest, src_user, signature_id, signature, action, cluster_id, final_anomaly_score, behavior_outlier
````

What this does:

- Creates three lookup definitions pointing to KVStore collections
- Allows | inputlookup auth_events_lookup to return the enriched event-level ML outputs
- Exposes user- and cluster-level behavioral profiles for dashboards and rules

## ğŸ“Œ 9.2. KVStore Collections (`collections.conf`)
The underlying KVStore schema is defined in `collections.conf`.

`collections.conf`

1ï¸âƒ£ Cluster Profiles

```
[auth_cluster_profiles]
field.type._key = string
field.type.cluster_id = string
field.type.event_count = string
field.type.user_count = string
field.type.hour_bin_mean = string
field.type.dow_mean = string
field.type.success_rate = string
field.type.private_ip_rate = string
field.type.signature_distribution = string
field.type.label = string
```

2ï¸âƒ£ User Profiles

```
[auth_user_profiles]
field.type._key = string
field.type.user = string
field.type.dominant_cluster = string
field.type.confidence = string
field.type.mean_hour = string
field.type.std_hour = string
```

3ï¸âƒ£ Event-Level Enriched Records

```
[auth_events]
field.type.TimeCreated = string
field.type.user = string
field.type.src = string
field.type.dest = string
field.type.src_user = string
field.type.signature_id = number
field.type.signature = string
field.type.action = string
field.type.process = string
field.type.cluster_id = number
field.type.outlier_score = number
field.type.cluster_rarity = number
field.type.signature_rarity = number
field.type.user_hour_score = number
field.type.final_anomaly_score = number
field.type.behavior_outlier = number
```

## ğŸ“Œ 9.3. ML Dashboard (Authentication ML Anomaly Detection Test)

A full-featured Splunk Dashboard is provided, built with:
- 3 main panels (User Overview / Cluster Analytics / Anomaly Explorer)
- Dynamic dropdowns for:
- User
- Cluster ID
- Anomaly Score threshold
- Time-range picker
- 13 data sources (| inputlookup)
- Visualizations: Table, Line Chart, Pie, Bubble, Area, Entropy table


Dashboard Capabilities:

```
Panel â†’ Description

User Behavior Overview â†’  Shows login patterns, cluster timeline, outliers over time
Cluster Analytics â†’ Cluster characteristics, signature distribution, cluster-level entropy
Anomaly Explorer â†’Outliers sorted by score, bubble anomaly map, high-risk timeline
```

Key Metrics visualized:

- Cluster distribution per user
- Behavior outliers over time
- Signature frequency
- Final anomaly score timeline
- Shannon entropy per cluster/signature
- High-risk events (score > threshold)
- Dominant cluster ID per user

The full XML/JSON of the dashboard is included in the section you provided. In the README, we summarize it without embedding the full XML.

## ğŸ“Œ 9.4. How Splunk & ML Sidecar Interact

```
ML Sidecar â†’ Updates KVStore collections
Splunk Dashboards â†’ Read from KVStore via inputlookup
```

The ML pipeline never writes to indexes â€” only to KVStore, which is ideal for continuously updated behavioral profiles.

## ğŸ“Œ 9.5. Validation Commands

You can confirm correct configuration using:

```
| inputlookup auth_events_lookup | head 5
```

```
| inputlookup auth_user_profiles_lookup 
```

```
| inputlookup auth_cluster_profiles_lookup 
```

---

# ğŸ“Œ 10. Installation & Execution Steps

1. Clone the project

```
git clone https://github.com/seynur/seynur-demos
cd seynur-demos/ml_sidecar
```

2. Install the package in development mode
```
pip install -e .
```

This makes the package importable without reinstalling during development.


3. Configure `settings.yaml`
You must edit:

```
ml_sidecar/settings.yaml
```

Key fields to update:

```
ingestion:
  earliest: -90d
  latest: now
  search_query: <your splunk search>

general:
  model_dir: ./model/
  model_name: kmeans_model.pkl

modeling:
  train_ratio: 0.8
  drift_threshold: 0.05

output:
  file:
    path: ./output/events.json

  splunk_kvstore:
    enabled: true
    base_url: https://127.0.0.1:8089
    auth_token: <splunk bearer token>
```

4. Run the full ML pipeline

```
python run_auto.py
```

This will:
- Fetch events from Splunk
- Train or load the model
- Run drift detection
- Compute anomaly scores
- Build user + cluster + event profiles
- Write results to KVStore

5. Validate KVStore content
Example SPL:

```
| inputlookup auth_events_lookup | head 20
```